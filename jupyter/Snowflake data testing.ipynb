{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a54a315c-49bc-48da-bb41-f7caba61dca5",
   "metadata": {},
   "source": [
    "# 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c48f383a-0349-430d-9250-b8feb0616795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random \n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# BigQuery\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Snowflake\n",
    "import snowflake.connector as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d7ea32-2faf-4551-8751-497e159e920a",
   "metadata": {},
   "source": [
    "# 2. Configure Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f0a14b-307d-484c-abd5-5d1086d877bc",
   "metadata": {},
   "source": [
    "## 2.1 BigQuey Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5d00bef-0c2d-411e-891b-21f805d44989",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_project_id = \"okta-ga-rollup\"\n",
    "bq_client = bigquery.Client(project=bq_project_id)\n",
    "timeout_seconds = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371c6cbc-ed0f-40aa-8b3c-9c601fea8ff1",
   "metadata": {},
   "source": [
    "## 2.2 Snoflake Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae13faad-1632-4205-ade6-565219fd2972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n",
      "Going to open: https://okta.okta.com/app/snowflake/exk1egd3l4qGXJ0YZ1d8/sso/saml?SAMLRequest=jZJRb9owFIX%2FSuQ9EzuBatQCKgorYwWKSlg33rzYgBfHTn0dAv9%2BTihT%2B9CqL5Zln%2BP7XZ%2FbuznmKjgIC9LoPopCggKhU8Ol3vXROrlrdVEAjmnOlNGij04C0M2gByxXBR2Wbq8fxXMpwAX%2BIQ20ueij0mpqGEigmuUCqEvpajif0TgktLDGmdQo9MrysYMBCOs84cXCQXq8vXMFxbiqqrBqh8bucEwIweQae1Ut%2BXLRH31P7%2BgjTDq13iu8fPnCdiv1%2BQs%2BwvpzFgH9niTL1vJhlaBgeEEdGQ1lLuxK2INMxfpxdgYAT%2FBwnwxD0KbaKpaJ1ORF6fxDod%2FhreBYmZ30vU7HfVRkku%2FIpnuYTDbz4j6fbbL1LWR%2F5wv1ND%2B1Ty4m68X%2B%2BmkxH%2FGr8luKgp%2BXMOM6zClAKaa6jtD5IxJftUjUittJ1KFtQsnXMI7IBgVjH6HUzDXOC6fJHAubpSZjRYH%2FQ2NxzCKx423VeZ78%2BkF%2BbyLexQAG13Gi84TQprodfKLvHn5teJmvhf%2Fy6XhplExPwZ2xOXPvJxKFUXMieWvbSKnImVRDzq0A8MkoZaqRFcz5MXa2FAgPzlXfDvLgHw%3D%3D&RelayState=ver%3A1-hint%3A34106439423778-ETMsDgAAAZSTkgJqABRBRVMvQ0JDL1BLQ1M1UGFkZGluZwEAABAAEGdz1LZdqRthoNMWPHKb7XcAAACAyE52yYdVK3EeOLtUksKFf2PlQK0tU3kVda6dinW%2F9QAmFSwNwmyMxMYdsOtOq7MFCtpRBKHOUnHIGcCWq1BprRX3wr5Ywv4khDNFbeNgKVmDtZFthNUMXrCNlAurBCnRFaq3LrfYa5W6OcnCxr0BfyRkiQ5AEx76UZCRhYFc0csAFK6WN5jIxUpYQuflYjM2VfwJ%2FC4V to authenticate...\n",
      "' '\n",
      "'Successfully connected to Snowflake'\n"
     ]
    }
   ],
   "source": [
    "# Snoflake credentials\n",
    "SNOWFLAKE_USER = 'vlad.parakhin@okta.com'\n",
    "SNOWFLAKE_AUTHENTICATOR = 'https://okta.okta.com'\n",
    "SNOWFLAKE_ACCOUNT = 'okta'\n",
    "SNOWFLAKE_PASSWORD = ' '\n",
    "SNOWFLAKE_WAREHOUSE = 'okta_dt_m'\n",
    "SNOWFLAKE_ROLE = 'digital_analytics_access_role'\n",
    "SNOWFLAKE_DB = 'OKTA'\n",
    "SNOWFLAKE_SCHEMA = 'OKTA_DT'\n",
    "\n",
    "\n",
    "conn = sf.connect(\n",
    "    user = SNOWFLAKE_USER, \n",
    "    authenticator='externalbrowser', \n",
    "    account = SNOWFLAKE_ACCOUNT, \n",
    "    password = SNOWFLAKE_PASSWORD,\n",
    "    warehouse = SNOWFLAKE_WAREHOUSE,\n",
    "    role = SNOWFLAKE_ROLE,\n",
    "    database = SNOWFLAKE_DB,\n",
    "    schema = SNOWFLAKE_SCHEMA\n",
    "    )\n",
    "\n",
    "cursor = conn.cursor()\n",
    "pprint(\" \")\n",
    "pprint(\"Successfully connected to Snowflake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad651cd-253c-41f4-910f-6daf9c544647",
   "metadata": {},
   "source": [
    "# 3. Define Test Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ecf141ca-e14b-48d7-b9cb-ea4581290dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLES_TO_TEST = [\n",
    "    {\n",
    "        \"bq_dataset\":\"dbt_prod_ga4_reporting\",\n",
    "        \"bq_table\":\"ga4__content_with_ua_union\",\n",
    "        \"sf_table\":\"GA4_CONTENT\",\n",
    "        \"agg_columns\":[\"unique_pageviews\", \"any_conversion_session_conversions_unique\"]\n",
    "    },\n",
    "    {\n",
    "        \"bq_dataset\":\"dbt_prod_ga4_reporting\",\n",
    "        \"bq_table\":\"ga4__traffic_with_ua_union\",\n",
    "        \"sf_table\":\"GA4_TRAFFIC\",\n",
    "        \"agg_columns\":[\"sessions\", \"high_value_visits\"]\n",
    "    },\n",
    "    {\n",
    "        \"bq_dataset\":\"dbt_prod_ga4_reporting\",\n",
    "        \"bq_table\":\"ga4__flattened_hits\",\n",
    "        \"sf_table\":\"GA4_HITS\",\n",
    "        \"agg_columns\": [\n",
    "            \"session_engaged\"\n",
    "        ],\n",
    "        \"custom_aggregates\": { \n",
    "           \"sum_flag_high_value\": \"CASE WHEN is_high_value_visit=TRUE THEN 1 ELSE 0 END\"\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70544e3-dc89-4a47-a596-11907c9be721",
   "metadata": {},
   "source": [
    "For MoM, QoQ, YoY checks define the time windows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5dbffc1b-c55d-4cb7-aad1-c484d675b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_windows = [\n",
    "    (\"2024-12-01\", \"2024-12-31\"),  # December 2024 (MoM example)\n",
    "    (\"2024-10-01\", \"2024-12-31\"),  # Q4 2024 (QoQ example)\n",
    "    (\"2024-01-01\", \"2024-12-31\")  # Full year 2024 (YoY example)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f168d7f-f50c-47de-8b87-d66b15a6c5ec",
   "metadata": {},
   "source": [
    "# 4. Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcc08ec-504b-49a6-8b53-c8ec50840573",
   "metadata": {},
   "source": [
    "## 4.1 Get Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b71d2f89-7c26-41dd-8b5e-8751f3747124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bq_schema(dataset_name, table_name):\n",
    "    query = f\"\"\"\n",
    "    SELECT column_name, data_type\n",
    "    FROM `{bq_project_id}.{dataset_name}.INFORMATION_SCHEMA.COLUMNS`\n",
    "    WHERE table_name = '{table_name}'\n",
    "    ORDER BY ordinal_position\n",
    "    \"\"\"\n",
    "    df = bq_client.query(query).to_dataframe()\n",
    "    return df\n",
    "\n",
    "def get_snowflake_schema(db, schema, table_name):\n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        column_name, \n",
    "        data_type \n",
    "    FROM {db}.information_schema.columns\n",
    "    WHERE table_name = '{table_name.upper()}'\n",
    "      AND table_schema = '{schema.upper()}'\n",
    "    ORDER BY ordinal_position\n",
    "    \"\"\"\n",
    "    return pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ab69d-402f-402f-bfed-155171f42344",
   "metadata": {},
   "source": [
    "## 4.2. Compare Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "75a67991-4226-45d3-bd92-8a93a5e5f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_schemas(bq_schema_df, sf_schema_df):\n",
    "    \"\"\"\n",
    "    Compare BigQuery and Snowflake schemas for missing, extra, or mismatched columns.\n",
    "    Adjusts for differences in data type representation between the two platforms.\n",
    "    \"\"\"\n",
    "    # Normalize BigQuery and Snowflake data types for comparison\n",
    "    type_mapping = {\n",
    "        'string': 'text',\n",
    "        'int64': 'number',\n",
    "        'float64': 'float',\n",
    "        'timestamp': 'timestamp_ntz',  \n",
    "        'boolean': 'boolean',\n",
    "        'date': 'date',\n",
    "        'datetime': 'timestamp',\n",
    "        'bool': 'boolean',\n",
    "        'array':'variant',\n",
    "        'struct':'variant'\n",
    "    }\n",
    "    \n",
    "    def normalize_type(data_type, mapping):\n",
    "        return mapping.get(data_type.lower(), data_type.lower())\n",
    "    \n",
    "    # Convert to dict: {column_name.lower(): normalized_data_type}\n",
    "    bq_cols = {\n",
    "        row[\"column_name\"].lower(): normalize_type(row[\"data_type\"], type_mapping)\n",
    "        for _, row in bq_schema_df.iterrows()\n",
    "    }\n",
    "    sf_cols = {\n",
    "        row[\"COLUMN_NAME\"].lower(): normalize_type(row[\"DATA_TYPE\"], type_mapping)\n",
    "        for _, row in sf_schema_df.iterrows()\n",
    "    }\n",
    "    \n",
    "    bq_set = set(bq_cols.keys())\n",
    "    sf_set = set(sf_cols.keys())\n",
    "    \n",
    "    missing_in_snowflake = bq_set - sf_set\n",
    "    extra_in_snowflake = sf_set - bq_set\n",
    "    \n",
    "    # For columns that exist in both, compare normalized data types\n",
    "    type_mismatches = []\n",
    "    for col in (bq_set & sf_set):\n",
    "        if bq_cols[col] != sf_cols[col]:\n",
    "            type_mismatches.append((col, bq_cols[col], sf_cols[col]))\n",
    "    \n",
    "    return missing_in_snowflake, extra_in_snowflake, type_mismatches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6097821a-3bee-48b9-a3a3-919928bb3275",
   "metadata": {},
   "source": [
    "## 4.3 Row Count & Aggregation Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "22e89998-45e8-4a1d-92d4-0ff952a00bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bq_row_count(dataset_name, table_name, start_date, end_date):  \n",
    "    query = f\"\"\"\n",
    "    SELECT COUNT(*) AS row_count\n",
    "    FROM `{bq_project_id}.{dataset_name}.{table_name}`\n",
    "    WHERE date >= '{start_date}' AND date <= '{end_date}'\n",
    "    \"\"\"\n",
    "    df = bq_client.query(query).to_dataframe()\n",
    "    return df[\"row_count\"].iloc[0]\n",
    "\n",
    "def get_sf_row_count(db, schema, table_name, start_date, end_date):\n",
    "    query = f\"\"\"\n",
    "    SELECT COUNT(*) AS ROW_COUNT\n",
    "    FROM {db}.{schema}.{table_name}\n",
    "    WHERE date >= '{start_date}' AND date <= '{end_date}'\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    return df[\"ROW_COUNT\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f3988616-c027-4377-8162-382bd8c6441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bq_aggregate(dataset_name, table_name, start_date, end_date, agg_column):\n",
    "    query = f\"\"\"\n",
    "    SELECT SUM({agg_column}) AS total_value\n",
    "    FROM `{bq_project_id}.{dataset_name}.{table_name}`\n",
    "    WHERE date >= '{start_date}' AND date <= '{end_date}'\n",
    "    \"\"\"\n",
    "    df = bq_client.query(query).to_dataframe()\n",
    "    df[\"total_value\"]= df[\"total_value\"].fillna(0)\n",
    "    return df[\"total_value\"].iloc[0]\n",
    "\n",
    "def get_sf_aggregate(db, schema, table_name, start_date, end_date, agg_column):\n",
    "    query = f\"\"\"\n",
    "    SELECT SUM({agg_column}) AS TOTAL_VALUE\n",
    "    FROM {db}.{schema}.{table_name}\n",
    "    WHERE date >= '{start_date}' AND date <= '{end_date}'\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    return df[\"TOTAL_VALUE\"].iloc[0] or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e09c5792-6e3d-49cf-9f25-b9bd751f5175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bq_custom_aggregate(dataset_name, table_name, start_date, end_date, agg_expr):\n",
    "    query = f\"\"\"\n",
    "    SELECT SUM({agg_expr}) AS custom_agg\n",
    "    FROM `{bq_project_id}.{dataset_name}.{table_name}`\n",
    "    WHERE date BETWEEN '{start_date}' AND '{end_date}'\n",
    "    \"\"\"\n",
    "    result = bq_client.query(query).to_dataframe()\n",
    "    return result[\"custom_agg\"].iloc[0] if not result.empty else 0\n",
    "\n",
    "def get_sf_custom_aggregate(db, schema, table_name, start_date, end_date, agg_expr):\n",
    "    query = f\"\"\"\n",
    "    SELECT SUM({agg_expr.strip()}) AS custom_agg\n",
    "    FROM {db}.{schema}.{table_name}\n",
    "    WHERE DATE BETWEEN '{start_date}' AND '{end_date}'\n",
    "    \"\"\"\n",
    "    \n",
    "    #print(f\"Executing Snowflake custom aggregate query:\\n{query}\")  # Debugging\n",
    "    result = pd.read_sql(query, conn)\n",
    "\n",
    "\n",
    "    if \"CUSTOM_AGG\" in result.columns:\n",
    "        value = result[\"CUSTOM_AGG\"].iloc[0]\n",
    "        return value if not result.empty else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf11f07e-db01-47d2-a096-7b4561fdc351",
   "metadata": {},
   "source": [
    "## 4.4 Random Sampling Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "de1db53a-f597-40dc-9432-4ffeb31ec5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_columns = [\"user_type\", \"country\", \"data_source\", \"date\", \"unique_pageviews\", \"last_non_direct_channel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "48d33068-f087-44f4-a186-6ed3b9798623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sample_check(dataset_name, bq_table, sf_table, start_date, end_date, sample_size=5):\n",
    "    \"\"\"\n",
    "    Perform a random sample check between BigQuery and Snowflake.\n",
    "    Dynamically handles column selection based on the schema.\n",
    "    \"\"\"\n",
    "    # Fetch the schema of the BigQuery table\n",
    "    bq_schema = get_bq_schema(dataset_name, bq_table)\n",
    "\n",
    "    # Ensure `bq_schema` is a list of dictionaries\n",
    "    if isinstance(bq_schema, pd.DataFrame):\n",
    "        bq_schema = bq_schema.to_dict(orient=\"records\")\n",
    "\n",
    "    # Extract available column names\n",
    "    available_columns = [col[\"column_name\"] for col in bq_schema]\n",
    "\n",
    "    # Define potential key columns to test\n",
    "    test_columns = [\"user_type\", \"country\", \"data_source\", \"date\", \"unique_pageviews\", \"last_non_direct_channel\"]\n",
    "    selected_columns = [col for col in test_columns if col in available_columns]\n",
    "\n",
    "    if not selected_columns:\n",
    "        return f\"No matching columns found for table {bq_table} to perform random sampling.\"\n",
    "\n",
    "    # Dynamically construct the SELECT statement\n",
    "    columns_to_query = \", \".join(selected_columns)\n",
    "    sample_query = f\"\"\"\n",
    "    SELECT {columns_to_query}\n",
    "    FROM `{bq_project_id}.{dataset_name}.{bq_table}`\n",
    "    WHERE DATE BETWEEN '{start_date}' AND '{end_date}'\n",
    "    AND {selected_columns[0]} IS NOT NULL\n",
    "    LIMIT 5000\n",
    "    \"\"\"\n",
    "    print(f\"Executing BigQuery random sampling query:\\n{sample_query}\")\n",
    "    df_candidates = bq_client.query(sample_query).to_dataframe()\n",
    "\n",
    "    if df_candidates.empty:\n",
    "        return f\"No data found in BigQuery table {bq_table} for the given date range.\"\n",
    "\n",
    "    # Randomly sample rows from the retrieved candidates\n",
    "    df_random = df_candidates.sample(n=min(sample_size, len(df_candidates)))\n",
    "\n",
    "    mismatch_count = 0\n",
    "\n",
    "    # Loop through sampled rows and check existence in Snowflake\n",
    "    for idx, row in df_random.iterrows():\n",
    "        # Dynamically build conditions for Snowflake query\n",
    "        conditions = []\n",
    "        for col in selected_columns:\n",
    "            if col == \"date\":\n",
    "                conditions.append(f\"TO_DATE({col}) = TO_DATE('{row[col]}')\")\n",
    "            elif isinstance(row[col], str):\n",
    "                conditions.append(f\"{col} = '{row[col]}'\")\n",
    "            else:\n",
    "                conditions.append(f\"{col} = {row[col]}\")\n",
    "        conditions_str = \" AND \".join(conditions)\n",
    "\n",
    "        sf_check_query = f\"\"\"\n",
    "        SELECT COUNT(*) AS CUSTOM_AGG\n",
    "        FROM {SNOWFLAKE_DB}.{SNOWFLAKE_SCHEMA}.{sf_table}\n",
    "        WHERE {conditions_str}\n",
    "        \"\"\"\n",
    "        print(f\"Executing Snowflake check query:\\n{sf_check_query}\")\n",
    "\n",
    "        try:\n",
    "            result = pd.read_sql(sf_check_query, conn)\n",
    "\n",
    "            if \"CUSTOM_AGG\" in result.columns:\n",
    "                count_in_sf = result[\"CUSTOM_AGG\"].iloc[0] if not result.empty else 0\n",
    "            else:\n",
    "                print(f\"  Column 'CUSTOM_AGG' is missing in the result.\")\n",
    "                count_in_sf = 0\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing Snowflake query: {e}\")\n",
    "            count_in_sf = 0\n",
    "\n",
    "        if count_in_sf == 0:\n",
    "            mismatch_count += 1\n",
    "\n",
    "    # Return results\n",
    "    if mismatch_count == 0:\n",
    "        return f\"All {sample_size} sampled rows exist in Snowflake.\"\n",
    "    else:\n",
    "        return f\"{mismatch_count} out of {sample_size} sampled rows not found in Snowflake.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d7dc5e-3537-4c50-a6bb-a1bdb5ec3f1a",
   "metadata": {},
   "source": [
    "# 5. Runt tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "22faa532-d65e-497b-adc4-cdcf3fa9fc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Table: BQ[dbt_prod_ga4_reporting.ga4__content_with_ua_union] vs SF[GA4_CONTENT] ---\n",
      "Schema Check Results:\n",
      "  No missing columns.\n",
      "  Extra in Snowflake: {'export_timestamp', 'batch_id'}\n",
      "  Type mismatch: conversions (BQ=array<struct<conversion_name string, on_page_conversions int64, on_page_conversion_value float64, converting_page_conversions int64, converting_page_conversion_value float64, session_conversions int64, session_conversions_unique int64, session_conversion_value float64, conversion_type string, conversion_type_group string>>, SF=variant)\n",
      "\n",
      "Date Range: 2024-12-01 to 2024-12-31\n",
      "   BQ row count: 8204534\n",
      "   SF row count: 8153241\n",
      "     unique_pageviews => BQ: 8207389, SF: 8186808, Diff%: 0.25\n",
      "     any_conversion_session_conversions_unique => BQ: 147051, SF: 146742, Diff%: 0.21\n",
      "\n",
      "Date Range: 2024-10-01 to 2024-12-31\n",
      "   BQ row count: 26399946\n",
      "   SF row count: 26284296\n",
      "     unique_pageviews => BQ: 26051381, SF: 26018155, Diff%: 0.13\n",
      "     any_conversion_session_conversions_unique => BQ: 433466, SF: 432959, Diff%: 0.12\n",
      "\n",
      "Date Range: 2024-01-01 to 2024-12-31\n",
      "   BQ row count: 104894946\n",
      "   SF row count: 104486755\n",
      "     unique_pageviews => BQ: 102997221, SF: 102963995, Diff%: 0.03\n",
      "     any_conversion_session_conversions_unique => BQ: 1573602, SF: 1573095, Diff%: 0.03\n",
      "\n",
      "--- Testing Table: BQ[dbt_prod_ga4_reporting.ga4__traffic_with_ua_union] vs SF[GA4_TRAFFIC] ---\n",
      "Schema Check Results:\n",
      "  No missing columns.\n",
      "  Extra in Snowflake: {'export_timestamp', 'batch_id'}\n",
      "  Type mismatch: conversions (BQ=array<struct<conversion_name string, conversions int64, unique_conversions int64, conversion_value float64, conversion_type string, conversion_type_group string>>, SF=variant)\n",
      "\n",
      "Date Range: 2024-12-01 to 2024-12-31\n",
      "   BQ row count: 23100983\n",
      "   SF row count: 23061045\n",
      "     sessions => BQ: 6507453, SF: 6508320, Diff%: 0.01\n",
      "     high_value_visits => BQ: 1072597, SF: 1072630, Diff%: 0.00\n",
      "\n",
      "Date Range: 2024-10-01 to 2024-12-31\n",
      "   BQ row count: 71872557\n",
      "   SF row count: 71758497\n",
      "     sessions => BQ: 20502694, SF: 20504330, Diff%: 0.01\n",
      "     high_value_visits => BQ: 3570165, SF: 3570241, Diff%: 0.00\n",
      "\n",
      "Date Range: 2024-01-01 to 2024-12-31\n",
      "   BQ row count: 299019579\n",
      "   SF row count: 298426923\n",
      "     sessions => BQ: 80983124, SF: 80984760, Diff%: 0.00\n",
      "     high_value_visits => BQ: 15228051, SF: 15228120, Diff%: 0.00\n",
      "\n",
      "--- Testing Table: BQ[dbt_prod_ga4_reporting.ga4__flattened_hits] vs SF[GA4_HITS] ---\n",
      "Schema Check Results:\n",
      "  No missing columns.\n",
      "  Extra in Snowflake: {'export_timestamp', 'batch_id'}\n",
      "  Type mismatch: last_event_ts (BQ=timestamp_ntz, SF=number)\n",
      "  Type mismatch: previous_conversion_converted_at (BQ=timestamp_ntz, SF=number)\n",
      "  Type mismatch: batch_page_id_rollup (BQ=array<int64>, SF=variant)\n",
      "  Type mismatch: previous_page_ts (BQ=timestamp_ntz, SF=number)\n",
      "  Type mismatch: event_timestamp_tz (BQ=timestamp, SF=number)\n",
      "  Type mismatch: session_start_at (BQ=timestamp_ntz, SF=number)\n",
      "  Type mismatch: event_timestamp (BQ=timestamp_ntz, SF=number)\n",
      "  Type mismatch: next_page_ts (BQ=timestamp_ntz, SF=number)\n",
      "\n",
      "Date Range: 2024-12-01 to 2024-12-31\n",
      "   BQ row count: 20458515\n",
      "   SF row count: 20457610\n",
      "     session_engaged => BQ: 12469440, SF: 12466951, Diff%: 0.02\n",
      "     sum_flag_high_value => BQ: 7662025, SF: 7659486, Diff%: 0.03\n",
      "\n",
      "Date Range: 2024-10-01 to 2024-12-31\n",
      "   BQ row count: 63945709\n",
      "   SF row count: 63955690\n",
      "     session_engaged => BQ: 40530496, SF: 40535945, Diff%: 0.01\n",
      "     sum_flag_high_value => BQ: 25042006, SF: 25043555, Diff%: 0.01\n",
      "\n",
      "Date Range: 2024-01-01 to 2024-12-31\n",
      "   BQ row count: 249441438\n",
      "   SF row count: 249452334\n",
      "     session_engaged => BQ: 162660060, SF: 162666420, Diff%: 0.00\n",
      "     sum_flag_high_value => BQ: 101363896, SF: 101366313, Diff%: 0.00\n"
     ]
    }
   ],
   "source": [
    "for table_map in TABLES_TO_TEST:\n",
    "    bq_dataset = table_map[\"bq_dataset\"]\n",
    "    bq_table = table_map[\"bq_table\"]\n",
    "    sf_table = table_map[\"sf_table\"]\n",
    "    agg_columns = table_map.get(\"agg_columns\", [])\n",
    "    custom_aggregates = table_map.get(\"custom_aggregates\", {})  # Fetch custom aggregates if defined\n",
    "    \n",
    "    print(f\"\\n--- Testing Table: BQ[{bq_dataset}.{bq_table}] vs SF[{sf_table}] ---\")\n",
    "    \n",
    "    # Schema Comparison\n",
    "    bq_schema = get_bq_schema(bq_dataset, bq_table)\n",
    "    sf_schema = get_snowflake_schema(SNOWFLAKE_DB, SNOWFLAKE_SCHEMA, sf_table)\n",
    "    missing_in_sf, extra_in_sf, type_mismatches = compare_schemas(bq_schema, sf_schema)\n",
    "    \n",
    "    print(\"Schema Check Results:\")\n",
    "    print(f\"  Missing in Snowflake: {missing_in_sf}\" if missing_in_sf else \"  No missing columns.\")\n",
    "    print(f\"  Extra in Snowflake: {extra_in_sf}\" if extra_in_sf else \"  No extra columns.\")\n",
    "    if type_mismatches:\n",
    "        for col, bq_type, sf_type in type_mismatches:\n",
    "            print(f\"  Type mismatch: {col} (BQ={bq_type}, SF={sf_type})\")\n",
    "    else:\n",
    "        print(\"  No data type mismatches.\")\n",
    "    \n",
    "    # Row Count & Aggregates by custom time windows\n",
    "    for start_date, end_date in time_windows:\n",
    "        bq_count = get_bq_row_count(bq_dataset, bq_table, start_date, end_date)\n",
    "        sf_count = get_sf_row_count(SNOWFLAKE_DB, SNOWFLAKE_SCHEMA, sf_table, start_date, end_date)\n",
    "        \n",
    "        print(f\"\\nDate Range: {start_date} to {end_date}\")\n",
    "        print(f\"   BQ row count: {bq_count}\")\n",
    "        print(f\"   SF row count: {sf_count}\")\n",
    "        \n",
    "        # Standard aggregates\n",
    "        for col in agg_columns:\n",
    "            bq_agg = get_bq_aggregate(bq_dataset, bq_table, start_date, end_date, col)\n",
    "            sf_agg = get_sf_aggregate(SNOWFLAKE_DB, SNOWFLAKE_SCHEMA, sf_table, start_date, end_date, col)\n",
    "            \n",
    "            difference_pct = (\n",
    "                0 if bq_agg == 0 and sf_agg == 0 else\n",
    "                abs(bq_agg - sf_agg) / bq_agg * 100 if bq_agg != 0 else 100\n",
    "            )\n",
    "            print(f\"     {col} => BQ: {bq_agg}, SF: {sf_agg}, Diff%: {difference_pct:.2f}\")\n",
    "        \n",
    "        # Custom aggregates\n",
    "        for agg_name, agg_expr in custom_aggregates.items():\n",
    "            bq_custom_agg = get_bq_custom_aggregate(bq_dataset, bq_table, start_date, end_date, agg_expr)\n",
    "            sf_custom_agg = get_sf_custom_aggregate(SNOWFLAKE_DB, SNOWFLAKE_SCHEMA, sf_table, start_date, end_date, agg_expr)\n",
    "            \n",
    "            difference_pct = (\n",
    "                0 if bq_custom_agg == 0 and sf_custom_agg == 0 else\n",
    "                abs(bq_custom_agg - sf_custom_agg) / bq_custom_agg * 100 if bq_custom_agg != 0 else 100\n",
    "            )\n",
    "            print(f\"     {agg_name} => BQ: {bq_custom_agg}, SF: {sf_custom_agg}, Diff%: {difference_pct:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9386c64b-042a-4bb7-b67e-88133fa053e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2b44a185-6953-47d3-a4a1-1d9f60b08abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing BigQuery random sampling query:\n",
      "\n",
      "    SELECT user_type, country, data_source, date, unique_pageviews, last_non_direct_channel\n",
      "    FROM `okta-ga-rollup.dbt_prod_ga4_reporting.ga4__content_with_ua_union`\n",
      "    WHERE DATE BETWEEN '2024-10-01' AND '2024-10-11'\n",
      "    AND user_type IS NOT NULL\n",
      "    LIMIT 5000\n",
      "    \n",
      "Executing Snowflake check query:\n",
      "\n",
      "        SELECT COUNT(*) AS CUSTOM_AGG\n",
      "        FROM OKTA.OKTA_DT.GA4_CONTENT\n",
      "        WHERE user_type = 'Returning User' AND country = 'United States' AND data_source = 'GA4' AND TO_DATE(date) = TO_DATE('2024-10-11') AND unique_pageviews = 1 AND last_non_direct_channel = 'Paid Search'\n",
      "        \n",
      "Executing Snowflake check query:\n",
      "\n",
      "        SELECT COUNT(*) AS CUSTOM_AGG\n",
      "        FROM OKTA.OKTA_DT.GA4_CONTENT\n",
      "        WHERE user_type = 'Returning User' AND country = 'United States' AND data_source = 'GA4' AND TO_DATE(date) = TO_DATE('2024-10-11') AND unique_pageviews = 1 AND last_non_direct_channel = 'Paid Search'\n",
      "        \n",
      "Executing Snowflake check query:\n",
      "\n",
      "        SELECT COUNT(*) AS CUSTOM_AGG\n",
      "        FROM OKTA.OKTA_DT.GA4_CONTENT\n",
      "        WHERE user_type = 'Returning User' AND country = 'United States' AND data_source = 'GA4' AND TO_DATE(date) = TO_DATE('2024-10-11') AND unique_pageviews = 1 AND last_non_direct_channel = 'Organic Search'\n",
      "        \n",
      "Executing Snowflake check query:\n",
      "\n",
      "        SELECT COUNT(*) AS CUSTOM_AGG\n",
      "        FROM OKTA.OKTA_DT.GA4_CONTENT\n",
      "        WHERE user_type = 'New User' AND country = 'United States' AND data_source = 'GA4' AND TO_DATE(date) = TO_DATE('2024-10-11') AND unique_pageviews = 1 AND last_non_direct_channel = 'Organic Search'\n",
      "        \n",
      "Executing Snowflake check query:\n",
      "\n",
      "        SELECT COUNT(*) AS CUSTOM_AGG\n",
      "        FROM OKTA.OKTA_DT.GA4_CONTENT\n",
      "        WHERE user_type = 'Returning User' AND country = 'United States' AND data_source = 'GA4' AND TO_DATE(date) = TO_DATE('2024-10-11') AND unique_pageviews = 1 AND last_non_direct_channel = 'Organic Search'\n",
      "        \n",
      "All 5 sampled rows exist in Snowflake.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_bq_dataset = \"dbt_prod_ga4_reporting\"\n",
    "test_bq_table = \"ga4__content_with_ua_union\"\n",
    "test_sf_table = \"GA4_CONTENT\"\n",
    "test_start_date = \"2024-10-01\"\n",
    "test_end_date = \"2024-10-11\"\n",
    "test_sample_size = 5\n",
    "\n",
    "result = random_sample_check(\n",
    "    dataset_name=test_bq_dataset,\n",
    "    bq_table=test_bq_table,\n",
    "    sf_table=test_sf_table,\n",
    "    start_date=test_start_date,\n",
    "    end_date=test_end_date,\n",
    "    sample_size=test_sample_size\n",
    ")\n",
    "\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d74224-7788-433d-88f8-ce43c2a82fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe3cd62-b9cc-45a2-898d-ca54a08af58a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988d5dd9-c6e6-47b9-9b2f-6ae13679417f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
